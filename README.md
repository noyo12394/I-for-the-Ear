

# I-for-the-Ear

**A YOLOv8-based model for real-time American Sign Language (ASL) detection and recognition.** This project leverages deep learning to accurately identify ASL hand gestures, aimed at improving communication accessibility for the Deaf and Hard of Hearing community.

## Project Motivation

Over **63 million individuals in India** experience some form of hearing impairment. My journey into this field began during an internship with **AuralApp** in Chennai, where I worked on enhancing an app designed to make **STEM education** more accessible for the Deaf community. This experience opened my eyes to the educational barriers faced by Deaf students, many of whom graduate with the vocabulary of a third or fourth grader due to lack of resources and support. This project is a step toward combating **audism** (oppression against the Deaf) by providing inclusive educational tools.

## Project Overview

This project, under the **Grand Challenge Scholars Program 2023-24** at Plaksha University, focuses on developing a **Sign-to-Text Language Converter** using **YOLOv8** for real-time gesture recognition. The ultimate goal is to enhance communication for Deaf students in educational settings, integrating this technology with other tools that visualize sound and provide real-time speech feedback.

### Key Components:
1. **Sign-to-Text Conversion Software**  
   - Real-time ASL gesture detection using YOLOv8.
   - User-friendly interface for classroom integration.

2. **Visualization of Sound through MATLAB Simulations**  
   - Visual tools to represent sound dynamics, like **Chladni plate vibrations**, for better STEM comprehension.

3. **Interactive Learning with PyGame**  
   - Games teaching **NCERT STEM concepts** in an engaging, accessible way.

4. **Real-Time Feedback & Speech Emotion Analysis**  
   - Analyzing speech patterns and emotions to improve communication skills for Deaf students.

## Technologies Used
- **YOLOv8** for gesture recognition.
- **MATLAB** for sound visualization simulations.
- **PyGame** for interactive educational tools.
- **Librosa** for audio processing and speech analysis.

## Objectives & Impact
- **Enhance Communication**: Breaking down language barriers through real-time gesture recognition.
- **Improve STEM Accessibility**: Making science and technology education more inclusive.
- **Foster Inclusivity**: Empowering Deaf students with tools for better academic and social outcomes.
- **Global Relevance**: Scalable solutions for educational institutions worldwide.

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/noyo12394/I-for-the-Ear.git
   cd I-for-the-Ear
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Run the application:
   ```bash
   python sign_language_detection.py
   ```

## Contributing
Contributions are welcome! Please open an issue or submit a pull request to improve this project.

---
